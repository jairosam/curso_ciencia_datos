{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-16T10:55:51-05:00\n",
      "\n",
      "CPython 3.7.6\n",
      "IPython 7.13.0\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.4.0-47-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descripcion</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aunque parezca mentira, las emisiones de dióxi...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hubo un proyecto impulsado por la Unión Europe...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China ha confirmado la conclusión con éxito de...</td>\n",
       "      <td>tecnología</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>En su fructífera carrera como humorista, actor...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tras dos años de negociación entre la instituc...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         descripcion   categoria\n",
       "0  Aunque parezca mentira, las emisiones de dióxi...     cultura\n",
       "1  Hubo un proyecto impulsado por la Unión Europe...     cultura\n",
       "2  China ha confirmado la conclusión con éxito de...  tecnología\n",
       "3  En su fructífera carrera como humorista, actor...     cultura\n",
       "4  Tras dos años de negociación entre la instituc...     cultura"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "noticias = pd.read_csv(\"noticias.csv\")\n",
    "noticias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo sera predecir la categoria de una noticia dada la descripción de esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cultura       9001\n",
       "tecnología    4198\n",
       "ocio          3296\n",
       "Name: categoria, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias.categoria.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a modificar este vectorizador para modificar dos parametros **strip_accents** que quita los acentos y **stop_words** que elimina las palabras que no tienen nigún sentido semantico es decir que no aportan nada al significado de la frase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"stopwords-es.json\") as fname:\n",
    "    stopwords_es = json.load(fname)\n",
    "\n",
    "vectorizador = TfidfVectorizer(strip_accents=\"unicode\", stop_words=stopwords_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '_',\n",
       " 'a',\n",
       " 'actualmente',\n",
       " 'acuerdo',\n",
       " 'adelante',\n",
       " 'ademas',\n",
       " 'además',\n",
       " 'adrede',\n",
       " 'afirmó',\n",
       " 'agregó',\n",
       " 'ahi',\n",
       " 'ahora',\n",
       " 'ahí',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'alguna',\n",
       " 'algunas',\n",
       " 'alguno',\n",
       " 'algunos',\n",
       " 'algún']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_es[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como nota el parametro StopWords tiene las palabras por defecto en ingles, sin embargo en español no las tiene, es decir que al vectorizador podriamos pasarle 'english' y sklearn ya tiene las stopwords en ingles definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<16495x59952 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 397698 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador.fit_transform(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16495, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class transformadorSparse(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn tiene tres implementaciones del clasificador que hacen esto y todas utilizan distribuciones de probabilidad distintas\n",
    "\n",
    "## GaussianNB: \n",
    "asume que los datos siguen una distribución Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gaussiano = make_pipeline(\n",
    "    vectorizador,\n",
    "    transformadorSparse(),\n",
    "    GaussianNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_seccionado = pd.DataFrame()\n",
    "noticias_seccionado[\"descripcion\"] = noticias.descripcion[:2000]\n",
    "noticias_seccionado[\"categoria\"] = noticias.categoria[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(stop_words=['0', '1', '2', '3', '4', '5', '6',\n",
       "                                             '7', '8', '9', '_', 'a',\n",
       "                                             'actualmente', 'acuerdo',\n",
       "                                             'adelante', 'ademas', 'además',\n",
       "                                             'adrede', 'afirmó', 'agregó',\n",
       "                                             'ahi', 'ahora', 'ahí', 'al',\n",
       "                                             'algo', 'alguna', 'algunas',\n",
       "                                             'alguno', 'algunos', 'algún', ...],\n",
       "                                 strip_accents='unicode')),\n",
       "                ('transformadorsparse', transformadorSparse()),\n",
       "                ('gaussiannb', GaussianNB())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_gaussiano.fit(X=noticias_seccionado.descripcion, y=noticias_seccionado.categoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nota\n",
    "\n",
    "La matriz es muy grande y ocupa toda la RAM del computador por eso se crea el DataSet *noticias_seccionado*\n",
    "\n",
    "Cuando tenga un mejor PC ver el video **108 naive bayes classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cultura', 'cultura', 'tecnología', ..., 'cultura', 'cultura',\n",
       "       'cultura'], dtype='<U10')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_gaussiano.predict(noticias_seccionado.descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-388a1677b3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_gaussiano\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoticias_seccionado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescripcion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoticias_seccionado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategoria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    404\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 248\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 score = scorer._score(cached_call, estimator,\n\u001b[0;32m---> 88\u001b[0;31m                                       *args, **kwargs)\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m--> 213\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1434\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1264\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipeline_gaussiano, noticias_seccionado.descripcion, noticias_seccionado.categoria, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al hacer validación cruzada esto arroja un error ya que nuestra variable objetivo es multiclase y la media definida para el cross_val_score es binaria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en la documentación se puede ver que la puntuación f1 nos permite 5 tipos de calculo para la media\n",
    "* **binary**: Devuelve la puntuación para la clase especificada en el argumento *pos_label*. Solo se puede aplicar en clasificación binaria. Este es el caso que se encuentra en formas de evaluación para modelos de clasificación\n",
    "\n",
    "* **micro**: Cuenta el número total de verdaderos positivos (TP), falsos negativos (FN) y falsos positivo (FP) y calcula una precisión y sensibilidad total y obtiene el F1, este metodo es mejor cuando se tienen clases no balanceadas (muchos casos más de una clase que de las demas o una distribución de datos asimetricas)\n",
    "\n",
    "* **macro**: calcula la precisión y la sensibilidad media de cada clase, hace su media aritmetica y calcula el parametro F1. (no tiene en cuenta las clases no balanceadas)\n",
    "\n",
    "* **weighted**: Calcula la precisión y sensibilidad media de cada clase, hace su media ponderada por el número de observaciones de cada clase y calcula el parametro F1.\n",
    "\n",
    "* **samples**\n",
    "\n",
    "Para solucionar este problema le pasamos el parametro *average* y le pasamos un tipo de calculo para multietiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.65  , 0.65  , 0.62  , 0.6475, 0.64  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1_multietiqueta(estimador, X, y):\n",
    "    preds = estimador.predict(X)\n",
    "    return f1_score(y, preds, average=\"micro\")\n",
    "\n",
    "cross_val_score(pipeline_gaussiano, noticias_seccionado.descripcion, noticias_seccionado.categoria, \n",
    "                scoring=f1_multietiqueta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede restringir la cantidad de palabras que considera el modelo con el parametro *max_features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gaussiano = make_pipeline(\n",
    "    TfidfVectorizer(strip_accents=\"unicode\", stop_words=stopwords_es, max_features=500),\n",
    "    transformadorSparse(),\n",
    "    GaussianNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.49  , 0.45  , 0.4875, 0.445 , 0.445 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline_gaussiano, noticias_seccionado.descripcion, noticias_seccionado.categoria, \n",
    "                scoring=f1_multietiqueta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las implementaciones más utilizadas para clasificación de texto son la [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) y la [BernoulliNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_multinomial = make_pipeline(\n",
    "    TfidfVectorizer(strip_accents=\"unicode\", stop_words=stopwords_es, max_features=1000),\n",
    "    transformadorSparse(),\n",
    "    MultinomialNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6675, 0.6775, 0.6725, 0.66  , 0.67  ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline_multinomial, noticias_seccionado.descripcion, noticias_seccionado.categoria, \n",
    "                scoring=f1_multietiqueta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial efectivamente funciona mejor que el Gaussiano\n",
    "\n",
    "Para Bernoulli debemos usar [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) ya que esta distribución solo considera dos valores 0 o 1 por tanto necesitamos las palabras como vectores binarios, además del parametro *binary=True* para que devuelva 1 o 0 en vez del numero de veces que aparece la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizador_count = CountVectorizer(stop_words=stopwords_es, binary=True, strip_accents=\"unicode\", \n",
    "                                     max_features=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *CountVectorizer* permite ver cuantas veces aparece cada palabra en el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tierra': 925,\n",
       " '30': 25,\n",
       " 'anos': 77,\n",
       " 'epoca': 337,\n",
       " 'principal': 763,\n",
       " 'estudio': 365,\n",
       " 'internacional': 504,\n",
       " 'publicado': 795,\n",
       " 'nature': 641,\n",
       " 'pasar': 705,\n",
       " 'proyecto': 789,\n",
       " 'union': 947,\n",
       " 'europea': 368,\n",
       " 'llegaron': 549,\n",
       " 'metodo': 598,\n",
       " 'aprender': 88,\n",
       " 'lengua': 530,\n",
       " 'espanol': 348,\n",
       " 'sistema': 880,\n",
       " 'espanoles': 351,\n",
       " 'puedan': 800,\n",
       " 'entender': 332,\n",
       " 'china': 167,\n",
       " 'confirmado': 209,\n",
       " 'exito': 375,\n",
       " 'operacion': 678,\n",
       " 'forma': 407,\n",
       " 'totalmente': 932,\n",
       " 'robot': 846,\n",
       " 'logro': 556,\n",
       " 'personal': 722,\n",
       " 'humano': 471,\n",
       " 'carrera': 155,\n",
       " 'actor': 49,\n",
       " 'director': 287,\n",
       " 'escritor': 343,\n",
       " 'decenas': 257,\n",
       " 'peliculas': 708,\n",
       " 'figuras': 400,\n",
       " 'importantes': 484,\n",
       " 'historia': 461,\n",
       " 'cine': 176,\n",
       " 'humor': 473,\n",
       " 'mayoria': 586,\n",
       " 'encuentran': 325,\n",
       " 'publico': 797,\n",
       " 'online': 677,\n",
       " 'mejores': 590,\n",
       " 'biblioteca': 121,\n",
       " 'museo': 631,\n",
       " 'finalmente': 402,\n",
       " 'siglo': 876,\n",
       " 'musica': 632,\n",
       " 'texto': 922,\n",
       " 'creado': 234,\n",
       " 'nombre': 653,\n",
       " 'obra': 664,\n",
       " 'video': 975,\n",
       " 'hombre': 464,\n",
       " 'comida': 195,\n",
       " 'muestra': 625,\n",
       " 'problema': 770,\n",
       " 'viajar': 971,\n",
       " 'usando': 951,\n",
       " 'google': 440,\n",
       " 'dando': 248,\n",
       " 'mundo': 630,\n",
       " 'lugares': 559,\n",
       " 'alguien': 61,\n",
       " 'ordenador': 683,\n",
       " 'punto': 804,\n",
       " 'rusia': 851,\n",
       " 'norte': 655,\n",
       " 'curioso': 246,\n",
       " 'america': 69,\n",
       " 'gracias': 441,\n",
       " 'empresas': 321,\n",
       " 'asociacion': 97,\n",
       " 'anuncio': 84,\n",
       " 'semana': 864,\n",
       " 'fabricantes': 384,\n",
       " 'demanda': 265,\n",
       " 'francia': 416,\n",
       " 'vida': 974,\n",
       " 'maquinas': 572,\n",
       " 'descubierto': 272,\n",
       " 'prueba': 790,\n",
       " 'piedra': 725,\n",
       " 'media': 587,\n",
       " '800': 36,\n",
       " 'kilometros': 524,\n",
       " 'construir': 220,\n",
       " 'tumba': 939,\n",
       " 'ano': 76,\n",
       " 'metros': 599,\n",
       " 'altura': 67,\n",
       " 'grande': 444,\n",
       " 'edad': 306,\n",
       " 'estructura': 363,\n",
       " 'artificial': 94,\n",
       " 'descubrimiento': 273,\n",
       " 'antiguo': 80,\n",
       " 'obras': 665,\n",
       " 'luz': 563,\n",
       " 'espanolas': 350,\n",
       " 'llevado': 551,\n",
       " 'cabo': 127,\n",
       " 'politicos': 741,\n",
       " 'dinero': 285,\n",
       " 'pequeno': 713,\n",
       " 'cuentas': 241,\n",
       " 'ocurre': 671,\n",
       " 'demuestra': 266,\n",
       " 'riesgo': 844,\n",
       " 'enfermedades': 330,\n",
       " 'personas': 723,\n",
       " 'peso': 724,\n",
       " 'normal': 654,\n",
       " 'debate': 251,\n",
       " 'torno': 931,\n",
       " 'idea': 475,\n",
       " 'decada': 255,\n",
       " 'importante': 483,\n",
       " 'vista': 984,\n",
       " 'salud': 854,\n",
       " 'publica': 792,\n",
       " 'unica': 944,\n",
       " 'frase': 419,\n",
       " 'ingles': 496,\n",
       " 'frances': 415,\n",
       " 'aleman': 59,\n",
       " 'ejemplos': 313,\n",
       " 'inicio': 497,\n",
       " 'castellano': 160,\n",
       " 'comic': 194,\n",
       " 'espanola': 349,\n",
       " 'chinos': 168,\n",
       " 'dejo': 264,\n",
       " 'carga': 153,\n",
       " 'artistas': 96,\n",
       " 'miguel': 603,\n",
       " 'familias': 390,\n",
       " 'especie': 354,\n",
       " 'comer': 193,\n",
       " 'evolucion': 372,\n",
       " 'seres': 869,\n",
       " 'humanos': 472,\n",
       " 'fuerza': 424,\n",
       " 'presion': 761,\n",
       " 'seleccion': 863,\n",
       " 'objetivo': 662,\n",
       " 'grupo': 445,\n",
       " 'virtual': 981,\n",
       " 'web': 992,\n",
       " 'internet': 506,\n",
       " 'ultimos': 943,\n",
       " 'convertido': 225,\n",
       " 'euros': 369,\n",
       " 'modelo': 614,\n",
       " 'trafico': 936,\n",
       " 'razon': 814,\n",
       " 'ambiente': 68,\n",
       " 'debemos': 252,\n",
       " 'ciencia': 170,\n",
       " 'capaz': 149,\n",
       " 'calle': 133,\n",
       " 'familia': 388,\n",
       " 'resultados': 842,\n",
       " 'nino': 649,\n",
       " 'nivel': 651,\n",
       " '70': 34,\n",
       " 'nasa': 637,\n",
       " 'ordenadores': 684,\n",
       " 'ayuda': 109,\n",
       " 'origen': 686,\n",
       " 'investigador': 508,\n",
       " 'trabajando': 934,\n",
       " 'ideas': 476,\n",
       " 'teoria': 918,\n",
       " 'universidad': 948,\n",
       " 'relacionada': 832,\n",
       " 'contrario': 223,\n",
       " 'especies': 355,\n",
       " 'medida': 588,\n",
       " 'afecta': 53,\n",
       " 'cultura': 245,\n",
       " 'importancia': 482,\n",
       " 'figura': 399,\n",
       " 'republica': 834,\n",
       " 'religion': 833,\n",
       " 'fotos': 414,\n",
       " 'febrero': 395,\n",
       " 'tipo': 926,\n",
       " 'rio': 845,\n",
       " 'campana': 139,\n",
       " 'cuerpo': 242,\n",
       " 'diario': 279,\n",
       " 'iba': 474,\n",
       " 'viaje': 972,\n",
       " 'muerte': 624,\n",
       " 'par': 697,\n",
       " 'mapas': 571,\n",
       " 'zona': 998,\n",
       " 'espana': 347,\n",
       " 'armas': 90,\n",
       " 'stephen': 897,\n",
       " 'series': 872,\n",
       " 'orden': 682,\n",
       " 'calidad': 131,\n",
       " 'frente': 420,\n",
       " 'pantalla': 695,\n",
       " 'lineas': 538,\n",
       " 'codigo': 186,\n",
       " 'probable': 767,\n",
       " 'numeros': 661,\n",
       " 'justo': 523,\n",
       " 'necesario': 643,\n",
       " 'fuente': 421,\n",
       " 'papel': 696,\n",
       " 'pueblo': 799,\n",
       " '12': 4,\n",
       " 'julio': 521,\n",
       " '000': 0,\n",
       " 'madrid': 565,\n",
       " 'centros': 165,\n",
       " 'barrio': 113,\n",
       " 'podian': 737,\n",
       " 'marzo': 579,\n",
       " '2016': 19,\n",
       " 'millones': 607,\n",
       " 'seguridad': 861,\n",
       " 'realmente': 818,\n",
       " 'meses': 597,\n",
       " 'septiembre': 868,\n",
       " '15': 7,\n",
       " 'publicada': 794,\n",
       " 'version': 968,\n",
       " 'exactamente': 373,\n",
       " 'provincia': 787,\n",
       " 'mujer': 627,\n",
       " '100': 2,\n",
       " 'habitantes': 451,\n",
       " 'llega': 546,\n",
       " 'ciudad': 177,\n",
       " '80': 35,\n",
       " 'economia': 304,\n",
       " 'plena': 734,\n",
       " 'servicios': 874,\n",
       " 'animal': 74,\n",
       " 'practicamente': 751,\n",
       " 'trabajadores': 933,\n",
       " 'empresa': 320,\n",
       " 'negocio': 644,\n",
       " 'mil': 604,\n",
       " 'ultima': 941,\n",
       " 'presentado': 758,\n",
       " 'gobierno': 439,\n",
       " 'huesos': 468,\n",
       " '11': 3,\n",
       " '14': 6,\n",
       " 'evento': 370,\n",
       " 'linux': 539,\n",
       " 'abierto': 38,\n",
       " 'edicion': 307,\n",
       " 'software': 888,\n",
       " 'libre': 533,\n",
       " 'creador': 235,\n",
       " 'control': 224,\n",
       " 'versiones': 969,\n",
       " 'entrevista': 336,\n",
       " 'the': 923,\n",
       " 'ley': 531,\n",
       " 'consumo': 221,\n",
       " 'sol': 889,\n",
       " 'fuerte': 423,\n",
       " 'producido': 775,\n",
       " 'cantidad': 145,\n",
       " 'ojos': 676,\n",
       " 'emision': 319,\n",
       " 'contenido': 222,\n",
       " 'puesto': 803,\n",
       " 'actualidad': 51,\n",
       " 'especialmente': 353,\n",
       " 'casos': 159,\n",
       " 'hijos': 460,\n",
       " 'programas': 783,\n",
       " 'atencion': 101,\n",
       " 'oceano': 669,\n",
       " 'atlantico': 102,\n",
       " 'mar': 573,\n",
       " 'costa': 231,\n",
       " 'canal': 142,\n",
       " 'realidad': 817,\n",
       " 'ocasiones': 668,\n",
       " 'conjunto': 210,\n",
       " 'construccion': 219,\n",
       " 'humana': 469,\n",
       " 'antigua': 79,\n",
       " 'europa': 367,\n",
       " 'situado': 884,\n",
       " 'titulo': 927,\n",
       " 'leer': 529,\n",
       " 'probablemente': 768,\n",
       " 'conocida': 213,\n",
       " 'actividad': 48,\n",
       " 'efecto': 311,\n",
       " 'cadena': 128,\n",
       " 'consecuencias': 216,\n",
       " 'conocemos': 212,\n",
       " 'acerca': 47,\n",
       " 'cambios': 138,\n",
       " 'profesor': 780,\n",
       " 'produce': 774,\n",
       " 'aspecto': 98,\n",
       " 'tenia': 916,\n",
       " 'planeta': 729,\n",
       " 'futuro': 430,\n",
       " 'oscura': 689,\n",
       " 'herramientas': 458,\n",
       " 'cambio': 137,\n",
       " 'social': 885,\n",
       " 'decadas': 256,\n",
       " 'viene': 978,\n",
       " 'duda': 301,\n",
       " 'acabo': 43,\n",
       " 'espacial': 345,\n",
       " 'equipo': 338,\n",
       " 'astronomos': 99,\n",
       " 'negro': 646,\n",
       " 'maximo': 583,\n",
       " 'temperatura': 913,\n",
       " 'anteriores': 78,\n",
       " 'lograr': 555,\n",
       " 'investigadores': 509,\n",
       " 'agua': 57,\n",
       " 'consiste': 218,\n",
       " '400': 30,\n",
       " 'capa': 146,\n",
       " 'completo': 201,\n",
       " 'gas': 432,\n",
       " 'dificil': 283,\n",
       " 'resulta': 840,\n",
       " 'superficie': 900,\n",
       " 'deberia': 253,\n",
       " 'seria': 870,\n",
       " 'puntos': 805,\n",
       " 'distancia': 292,\n",
       " 'centro': 164,\n",
       " 'agosto': 56,\n",
       " 'francisco': 417,\n",
       " 'franco': 418,\n",
       " 'arte': 91,\n",
       " 'paso': 706,\n",
       " 'siglos': 877,\n",
       " 'propiedad': 784,\n",
       " 'gente': 435,\n",
       " 'utiliza': 954,\n",
       " 'mensajes': 594,\n",
       " 'incluyendo': 488,\n",
       " 'marcas': 575,\n",
       " 'moviles': 620,\n",
       " 'traves': 938,\n",
       " 'marca': 574,\n",
       " 'problemas': 771,\n",
       " 'enfermedad': 329,\n",
       " 'acceder': 44,\n",
       " 'digital': 284,\n",
       " 'libros': 536,\n",
       " 'industria': 490,\n",
       " 'existencia': 374,\n",
       " 'libro': 535,\n",
       " 'venta': 965,\n",
       " 'george': 436,\n",
       " 'entorno': 333,\n",
       " 'asunto': 100,\n",
       " 'oficial': 673,\n",
       " 'llego': 550,\n",
       " 'lago': 526,\n",
       " 'investigacion': 507,\n",
       " 'servicio': 873,\n",
       " 'cliente': 182,\n",
       " 'responsable': 835,\n",
       " 'comunicacion': 203,\n",
       " 'national': 638,\n",
       " 'twitter': 940,\n",
       " 'encontrado': 322,\n",
       " 'imagenes': 479,\n",
       " 'termino': 919,\n",
       " 'nacional': 636,\n",
       " 'natural': 639,\n",
       " 'unidos': 946,\n",
       " 'local': 553,\n",
       " '60': 33,\n",
       " 'palabras': 694,\n",
       " 'viernes': 979,\n",
       " 'encontrar': 323,\n",
       " 'documento': 298,\n",
       " 'clave': 181,\n",
       " 'archivos': 89,\n",
       " 'octubre': 670,\n",
       " 'pruebas': 791,\n",
       " '22': 21,\n",
       " '18': 10,\n",
       " 'datos': 249,\n",
       " 'cientificos': 174,\n",
       " 'vuelta': 989,\n",
       " 'saturno': 856,\n",
       " 'planta': 730,\n",
       " 'produccion': 773,\n",
       " 'electrico': 317,\n",
       " 'york': 996,\n",
       " 'mes': 596,\n",
       " 'coche': 184,\n",
       " 'rapido': 812,\n",
       " 'velocidad': 961,\n",
       " 'cabeza': 126,\n",
       " 'virus': 982,\n",
       " 'dudas': 302,\n",
       " 'naturaleza': 640,\n",
       " 'joven': 516,\n",
       " 'llamado': 545,\n",
       " 'instituto': 498,\n",
       " 'premio': 755,\n",
       " 'of': 672,\n",
       " 'londres': 557,\n",
       " 'fotografias': 412,\n",
       " 'alla': 64,\n",
       " 'carlos': 154,\n",
       " 'lunes': 562,\n",
       " 'popular': 743,\n",
       " 'serie': 871,\n",
       " 'mexico': 600,\n",
       " 'hechos': 456,\n",
       " 'documental': 297,\n",
       " 'numero': 660,\n",
       " 'concepto': 206,\n",
       " '500': 32,\n",
       " 'estudios': 366,\n",
       " 'fabrica': 382,\n",
       " 'ii': 477,\n",
       " 'logrado': 554,\n",
       " '19': 11,\n",
       " 'vivio': 986,\n",
       " '300': 26,\n",
       " 'cuya': 247,\n",
       " 'caracteristicas': 152,\n",
       " 'comun': 202,\n",
       " 'estilo': 360,\n",
       " 'coleccion': 187,\n",
       " 'videojuegos': 976,\n",
       " 'noche': 652,\n",
       " 'diciembre': 280,\n",
       " 'dejado': 262,\n",
       " 'presencia': 757,\n",
       " 'accion': 46,\n",
       " 'actual': 50,\n",
       " 'situacion': 883,\n",
       " 'plan': 728,\n",
       " 'combatir': 191,\n",
       " 'ciudadanos': 178,\n",
       " 'desarrollo': 271,\n",
       " 'opinion': 680,\n",
       " 'comunicado': 204,\n",
       " 'puedes': 801,\n",
       " 'carta': 156,\n",
       " 'jamas': 512,\n",
       " '20': 12,\n",
       " 'profundidad': 781,\n",
       " 'entrada': 334,\n",
       " 'camara': 134,\n",
       " 'verano': 966,\n",
       " 'noticia': 657,\n",
       " 'espacio': 346,\n",
       " 'partido': 703,\n",
       " 'usado': 950,\n",
       " 'puerta': 802,\n",
       " 'sitios': 882,\n",
       " 'encontro': 324,\n",
       " 'cambiar': 136,\n",
       " 'decidio': 259,\n",
       " 'vender': 964,\n",
       " 'utilizan': 955,\n",
       " 'productos': 777,\n",
       " 'funcionamiento': 428,\n",
       " 'universo': 949,\n",
       " '40': 29,\n",
       " 'hora': 467,\n",
       " '50': 31,\n",
       " 'tantos': 904,\n",
       " 'profesionales': 779,\n",
       " 'cuestion': 244,\n",
       " 'adn': 52,\n",
       " 'hallazgo': 455,\n",
       " 'herramienta': 457,\n",
       " 'lucha': 558,\n",
       " 'cancer': 143,\n",
       " 'explica': 378,\n",
       " 'escrito': 342,\n",
       " 'redes': 825,\n",
       " 'imperio': 481,\n",
       " 'mensaje': 593,\n",
       " 'deja': 261,\n",
       " 'proceso': 772,\n",
       " 'recientemente': 820,\n",
       " 'restos': 839,\n",
       " 'ejercito': 314,\n",
       " 'evitar': 371,\n",
       " 'posibles': 747,\n",
       " 'increible': 489,\n",
       " 'llamada': 543,\n",
       " 'marcha': 576,\n",
       " 'alemania': 60,\n",
       " 'estacion': 357,\n",
       " 'coches': 185,\n",
       " 'trabajos': 935,\n",
       " 'rapida': 811,\n",
       " 'responsables': 836,\n",
       " 'pelicula': 707,\n",
       " 'casa': 157,\n",
       " 'mano': 568,\n",
       " 'materiales': 582,\n",
       " 'hombres': 465,\n",
       " 'deberian': 254,\n",
       " 'enero': 328,\n",
       " 'luna': 561,\n",
       " 'invierno': 510,\n",
       " 'xx': 995,\n",
       " 'cientificas': 172,\n",
       " 'fisica': 403,\n",
       " 'famosa': 391,\n",
       " 'especial': 352,\n",
       " 'principio': 765,\n",
       " 'guia': 447,\n",
       " 'anunciado': 83,\n",
       " 'ee': 309,\n",
       " 'conocido': 214,\n",
       " 'companias': 198,\n",
       " 'red': 824,\n",
       " 'tecnologia': 908,\n",
       " 'llegado': 547,\n",
       " 'fabricacion': 383,\n",
       " 'plaza': 733,\n",
       " 'dejar': 263,\n",
       " 'comunidad': 205,\n",
       " 'garcia': 431,\n",
       " 'publicar': 796,\n",
       " 'estandar': 359,\n",
       " 'acceso': 45,\n",
       " 'decision': 260,\n",
       " 'parque': 700,\n",
       " 'isla': 511,\n",
       " 'visto': 985,\n",
       " 'comienza': 196,\n",
       " 'habian': 450,\n",
       " 'superior': 901,\n",
       " 'resto': 838,\n",
       " 'guerra': 446,\n",
       " 'mundial': 629,\n",
       " 'japon': 513,\n",
       " 'ministerio': 608,\n",
       " 'movimientos': 622,\n",
       " 'acaba': 41,\n",
       " 'programa': 782,\n",
       " 'usuarios': 953,\n",
       " 'disponible': 289,\n",
       " 'pagina': 691,\n",
       " 'destino': 276,\n",
       " 'blog': 123,\n",
       " 'cientifico': 173,\n",
       " 'desarrollado': 269,\n",
       " 'generacion': 433,\n",
       " 'permite': 718,\n",
       " 'pequenas': 712,\n",
       " 'real': 816,\n",
       " 'animales': 75,\n",
       " 'rel': 830,\n",
       " 'energetica': 326,\n",
       " 'imagen': 478,\n",
       " 'manos': 569,\n",
       " 'llama': 542,\n",
       " 'partes': 701,\n",
       " 'perros': 719,\n",
       " 'caso': 158,\n",
       " 'aire': 58,\n",
       " 'acaban': 42,\n",
       " 'plantas': 731,\n",
       " 'energia': 327,\n",
       " 'solar': 890,\n",
       " 'record': 821,\n",
       " 'capacidad': 148,\n",
       " 'nuclear': 659,\n",
       " 'civil': 179,\n",
       " 'compania': 197,\n",
       " 'aplicacion': 86,\n",
       " '10': 1,\n",
       " 'larga': 527,\n",
       " 'abrir': 40,\n",
       " 'vehiculos': 960,\n",
       " 'crear': 237,\n",
       " 'momentos': 615,\n",
       " 'artista': 95,\n",
       " 'sector': 857,\n",
       " 'referencia': 826,\n",
       " 'paises': 693,\n",
       " 'revista': 843,\n",
       " 'cientifica': 171,\n",
       " 'articulos': 93,\n",
       " 'expertos': 377,\n",
       " 'articulo': 92,\n",
       " 'unico': 945,\n",
       " 'capaces': 147,\n",
       " 'robots': 847,\n",
       " 'sistemas': 881,\n",
       " 'cuerpos': 243,\n",
       " 'siguen': 878,\n",
       " 'material': 581,\n",
       " 'sociedad': 887,\n",
       " 'persona': 720,\n",
       " 'algun': 62,\n",
       " 'rojo': 849,\n",
       " 'recuerda': 823,\n",
       " 'precio': 752,\n",
       " 'memoria': 591,\n",
       " 'raro': 813,\n",
       " 'sentido': 867,\n",
       " 'satelite': 855,\n",
       " 'pequena': 711,\n",
       " 'historica': 462,\n",
       " 'region': 827,\n",
       " 'periodo': 717,\n",
       " 'diseno': 288,\n",
       " 'bateria': 116,\n",
       " 'primeras': 762,\n",
       " 'internacionales': 505,\n",
       " 'vineta': 980,\n",
       " 'influencia': 491,\n",
       " 'negra': 645,\n",
       " 'ficcion': 398,\n",
       " 'experimento': 376,\n",
       " 'diversas': 296,\n",
       " 'parecer': 699,\n",
       " 'xix': 994,\n",
       " 'agentes': 55,\n",
       " 'madre': 564,\n",
       " 'fuentes': 422,\n",
       " 'salir': 853,\n",
       " 'plataforma': 732,\n",
       " 'objetos': 663,\n",
       " 'marte': 577,\n",
       " 'jupiter': 522,\n",
       " 'falta': 387,\n",
       " 'descubrir': 275,\n",
       " 'podia': 736,\n",
       " 'literalmente': 541,\n",
       " 'original': 687,\n",
       " 'incluye': 487,\n",
       " 'escribir': 341,\n",
       " 'agencia': 54,\n",
       " 'tratamiento': 937,\n",
       " 'segundos': 860,\n",
       " 'seguir': 859,\n",
       " 'android': 73,\n",
       " 'gigante': 437,\n",
       " 'posibilidad': 746,\n",
       " '200': 13,\n",
       " 'militar': 606,\n",
       " 'mision': 611,\n",
       " 'campo': 140,\n",
       " 'oro': 688,\n",
       " 'estrella': 361,\n",
       " 'tecnicas': 907,\n",
       " 'fotografia': 411,\n",
       " 'camaras': 135,\n",
       " 'tenian': 917,\n",
       " 'recorrido': 822,\n",
       " 'vehiculo': 959,\n",
       " 'crecimiento': 238,\n",
       " 'cerebro': 166,\n",
       " 'tamano': 903,\n",
       " 'pequenos': 714,\n",
       " 'fascinante': 394,\n",
       " 'television': 911,\n",
       " 'derechos': 268,\n",
       " 'autor': 103,\n",
       " 'informe': 494,\n",
       " 'muestran': 626,\n",
       " 'linea': 537,\n",
       " 'ningun': 648,\n",
       " 'noticias': 658,\n",
       " 'nacio': 635,\n",
       " 'interior': 503,\n",
       " 'causa': 161,\n",
       " 'profesional': 778,\n",
       " 'ultimas': 942,\n",
       " '23': 22,\n",
       " 'jovenes': 517,\n",
       " 'busca': 125,\n",
       " 'informacion': 492,\n",
       " 'rodea': 848,\n",
       " 'facebook': 385,\n",
       " 'funciona': 427,\n",
       " 'propuesta': 786,\n",
       " 'nave': 642,\n",
       " 'condiciones': 208,\n",
       " 'david': 250,\n",
       " 'famoso': 392,\n",
       " 'reciente': 819,\n",
       " 'respuesta': 837,\n",
       " 'correo': 228,\n",
       " 'electronico': 318,\n",
       " 'conoce': 211,\n",
       " 'vemos': 962,\n",
       " 'aplicaciones': 87,\n",
       " 'hablar': 453,\n",
       " 'creadores': 236,\n",
       " 'distintos': 294,\n",
       " 'uu': 957,\n",
       " 'diferencia': 282,\n",
       " 'fans': 393,\n",
       " '90': 37,\n",
       " 'vuelve': 991,\n",
       " 'minutos': 610,\n",
       " 'california': 132,\n",
       " 'interesante': 502,\n",
       " 'caja': 130,\n",
       " 'basura': 115,\n",
       " 'semanas': 865,\n",
       " 'vuelto': 990,\n",
       " 'informatica': 493,\n",
       " 'fenomeno': 397,\n",
       " 'educacion': 308,\n",
       " 'fecha': 396,\n",
       " 'nacimiento': 634,\n",
       " 'personajes': 721,\n",
       " 'suelo': 899,\n",
       " 'estadounidense': 358,\n",
       " 'sale': 852,\n",
       " 'poblacion': 735,\n",
       " 'relacion': 831,\n",
       " 'principios': 766,\n",
       " 'particulas': 702,\n",
       " 'alta': 65,\n",
       " 'directamente': 286,\n",
       " 'fotografo': 413,\n",
       " 'ingeniero': 495,\n",
       " 'movimiento': 621,\n",
       " 'finales': 401,\n",
       " 'tecnica': 906,\n",
       " '2015': 18,\n",
       " 'humanidad': 470,\n",
       " 'razones': 815,\n",
       " 'aviones': 108,\n",
       " 'cielo': 169,\n",
       " 'explicacion': 379,\n",
       " 'motivo': 617,\n",
       " 'capital': 150,\n",
       " 'explicar': 380,\n",
       " 'amor': 71,\n",
       " 'perdido': 715,\n",
       " 'mayores': 585,\n",
       " 'distribucion': 295,\n",
       " 'anuncia': 82,\n",
       " 'efectos': 312,\n",
       " 'decidido': 258,\n",
       " 'juegos': 520,\n",
       " 'miles': 605,\n",
       " 'compartir': 199,\n",
       " 'sociales': 886,\n",
       " 'mercado': 595,\n",
       " 'tendencia': 914,\n",
       " 'nacido': 633,\n",
       " 'autores': 104,\n",
       " 'publicacion': 793,\n",
       " 'ocasion': 667,\n",
       " 'policia': 739,\n",
       " 'cientos': 175,\n",
       " 'impresionante': 486,\n",
       " 'comenzo': 192,\n",
       " 'blanco': 122,\n",
       " 'global': 438,\n",
       " 'lee': 528,\n",
       " 'volver': 988,\n",
       " 'dolares': 300,\n",
       " 'baja': 111,\n",
       " 'telefono': 910,\n",
       " 'suele': 898,\n",
       " 'concreto': 207,\n",
       " 'departamento': 267,\n",
       " 'principales': 764,\n",
       " 'portatil': 745,\n",
       " 'detectar': 278,\n",
       " 'dispositivo': 290,\n",
       " 'corazon': 227,\n",
       " 'operativo': 679,\n",
       " 'windows': 993,\n",
       " 'usuario': 952,\n",
       " 'tendra': 915,\n",
       " 'base': 114,\n",
       " 'manana': 566,\n",
       " 'completamente': 200,\n",
       " 'libres': 534,\n",
       " 'sonda': 892,\n",
       " 'abril': 39,\n",
       " 'detalles': 277,\n",
       " 'genero': 434,\n",
       " 'ofrece': 674,\n",
       " 'observar': 666,\n",
       " 'habra': 454,\n",
       " 'dura': 303,\n",
       " 'rajoy': 810,\n",
       " 'senor': 866,\n",
       " 'ninos': 650,\n",
       " 'piel': 726,\n",
       " '2013': 16,\n",
       " 'aparece': 85,\n",
       " 'polemica': 738,\n",
       " 'impacto': 480,\n",
       " 'tecnologico': 909,\n",
       " 'escuchar': 344,\n",
       " 'tiempos': 924,\n",
       " '2000': 14,\n",
       " 'alto': 66,\n",
       " 'posicion': 748,\n",
       " 'motor': 618,\n",
       " 'mayo': 584,\n",
       " 'reino': 829,\n",
       " 'mapa': 570,\n",
       " 'enorme': 331,\n",
       " 'quedado': 808,\n",
       " 'new': 647,\n",
       " 'regiones': 828,\n",
       " 'orbita': 681,\n",
       " 'mujeres': 628,\n",
       " 'familiar': 389,\n",
       " 'organizacion': 685,\n",
       " 'manel': 567,\n",
       " 'fontdevila': 406,\n",
       " 'eldiario': 315,\n",
       " 'grafeno': 442,\n",
       " 'llevan': 552,\n",
       " 'sexo': 875,\n",
       " 'gusta': 448,\n",
       " 'foto': 410,\n",
       " 'sorprendente': 894,\n",
       " 'funcion': 426,\n",
       " 'vivir': 987,\n",
       " 'aves': 106,\n",
       " 'post': 749,\n",
       " 'campos': 141,\n",
       " '16': 8,\n",
       " 'nota': 656,\n",
       " 'rover': 850,\n",
       " 'sorpresa': 895,\n",
       " 'tomada': 928,\n",
       " 'fuerzas': 425,\n",
       " 'producto': 776,\n",
       " 'hogar': 463,\n",
       " 'tesla': 921,\n",
       " 'queria': 809,\n",
       " 'presente': 759,\n",
       " 'juego': 519,\n",
       " 'pasa': 704,\n",
       " 'extrano': 381,\n",
       " 'medios': 589,\n",
       " 'cualquiera': 240,\n",
       " 'tema': 912,\n",
       " '2012': 15,\n",
       " 'queda': 807,\n",
       " 'bernardo': 120,\n",
       " 'vergara': 967,\n",
       " 'seguro': 862,\n",
       " 'ofrecer': 675,\n",
       " 'clase': 180,\n",
       " 'movil': 619,\n",
       " 'precisamente': 753,\n",
       " 'espectaculares': 356,\n",
       " 'utilizar': 956,\n",
       " 'tarea': 905,\n",
       " 'parecen': 698,\n",
       " 've': 958,\n",
       " 'facil': 386,\n",
       " 'imposible': 485,\n",
       " 'soldados': 891,\n",
       " 'sur': 902,\n",
       " 'central': 163,\n",
       " '3d': 28,\n",
       " 'celulas': 162,\n",
       " 'lista': 540,\n",
       " 'resultado': 841,\n",
       " 'interes': 501,\n",
       " '13': 5,\n",
       " 'amigos': 70,\n",
       " 'antiguos': 81,\n",
       " 'corta': 229,\n",
       " 'luis': 560,\n",
       " 'documentos': 299,\n",
       " 'diez': 281,\n",
       " 'tomar': 930,\n",
       " 'clientes': 183,\n",
       " 'movistar': 623,\n",
       " 'habitual': 452,\n",
       " 'puso': 806,\n",
       " 'azul': 110,\n",
       " 'jose': 515,\n",
       " 'vision': 983,\n",
       " 'menor': 592,\n",
       " 'zonas': 999,\n",
       " 'fondo': 405,\n",
       " 'llegar': 548,\n",
       " 'tomadas': 929,\n",
       " '25': 24,\n",
       " 'libertad': 532,\n",
       " 'haberse': 449,\n",
       " 'pp': 750,\n",
       " 'john': 514,\n",
       " 'prensa': 756,\n",
       " 'creacion': 233,\n",
       " 'peninsula': 709,\n",
       " 'ministro': 609,\n",
       " 'cara': 151,\n",
       " 'barcelona': 112,\n",
       " 'martin': 578,\n",
       " 'dispositivos': 291,\n",
       " 'alimentos': 63,\n",
       " 'intencion': 500,\n",
       " 'honor': 466,\n",
       " 'via': 970,\n",
       " 'desarrolladores': 270,\n",
       " 'descubrio': 274,\n",
       " 'caida': 129,\n",
       " 'conseguido': 217,\n",
       " 'analisis': 72,\n",
       " 'escena': 340,\n",
       " 'videos': 977,\n",
       " 'fisico': 404,\n",
       " 'youtube': 997,\n",
       " 'funcionar': 429,\n",
       " 'seguidores': 858,\n",
       " 'com': 190,\n",
       " 'formas': 409,\n",
       " 'pone': 742,\n",
       " 'inteligencia': 499,\n",
       " 'pablo': 690,\n",
       " 'colores': 189,\n",
       " 'cosa': 230,\n",
       " 'soporte': 893,\n",
       " 'materia': 580,\n",
       " '17': 9,\n",
       " 'paginas': 692,\n",
       " 'convirtio': 226,\n",
       " 'moda': 613,\n",
       " 'eeuu': 310,\n",
       " 'escala': 339,\n",
       " 'avion': 107,\n",
       " '21': 20,\n",
       " 'coste': 232,\n",
       " '35': 27,\n",
       " 'estrellas': 362,\n",
       " 'estudiantes': 364,\n",
       " 'britanico': 124,\n",
       " 'beneficios': 119,\n",
       " 'forman': 408,\n",
       " 'crisis': 239,\n",
       " 'economica': 305,\n",
       " '2014': 17,\n",
       " '24': 23,\n",
       " 'miercoles': 602,\n",
       " 'michael': 601,\n",
       " 'juan': 518,\n",
       " 'distintas': 293,\n",
       " 'color': 188,\n",
       " 'pregunta': 754,\n",
       " 'presidente': 760,\n",
       " 'ven': 963,\n",
       " 'mitad': 612,\n",
       " 'bbc': 118,\n",
       " 'autoridades': 105,\n",
       " 'proxima': 788,\n",
       " 'electrica': 316,\n",
       " 'conocidos': 215,\n",
       " 'mora': 616,\n",
       " 'politica': 740,\n",
       " 'probar': 769,\n",
       " 'grafico': 443,\n",
       " 'propiedades': 785,\n",
       " 'llamadas': 544,\n",
       " 'pudiera': 798,\n",
       " 'periodista': 716,\n",
       " 'pirate': 727,\n",
       " 'bay': 117,\n",
       " 'victimas': 973,\n",
       " 'entrar': 335,\n",
       " 'pensar': 710,\n",
       " 'terreno': 920,\n",
       " 'populares': 744,\n",
       " 'laboratorio': 525,\n",
       " 'cancion': 144,\n",
       " 'star': 896,\n",
       " 'simplemente': 879,\n",
       " 'hielo': 459}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_count.fit(noticias_seccionado.descripcion, noticias_seccionado.categoria)\n",
    "vectorizador_count.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bernoulli = make_pipeline(\n",
    "    vectorizador_count,\n",
    "    transformadorSparse(),\n",
    "    BernoulliNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/buitrago/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6725, 0.6475, 0.64  , 0.6   , 0.6525])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline_bernoulli, noticias_seccionado.descripcion, noticias_seccionado.categoria, \n",
    "                scoring=f1_multietiqueta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo funciona incluso mejor que los dos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
